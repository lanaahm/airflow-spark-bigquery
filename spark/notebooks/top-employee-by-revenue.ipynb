{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15f92200",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "24/06/22 18:34:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/06/22 18:34:24 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "24/06/22 18:34:24 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Check if the JDBC driver exists\n",
    "jdbc_driver_path = \"/home/user/work/jars/postgresql-42.7.3.jar\"\n",
    "if not os.path.isfile(jdbc_driver_path):\n",
    "    raise FileNotFoundError(f\"The JDBC driver was not found at the specified path: {jdbc_driver_path}\")\n",
    "\n",
    "# Initialize the Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"PostgreSQL to PySpark\") \\\n",
    "    .config(\"spark.jars\", jdbc_driver_path) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# PostgreSQL connection properties\n",
    "jdbc_url = \"jdbc:postgresql://postgres-staging:5432/staging_db\"\n",
    "connection_properties = {\n",
    "    \"user\": \"admin\",\n",
    "    \"password\": \"admin\",\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe047ec",
   "metadata": {},
   "source": [
    "## Top Employee by Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63d459d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:==============================================>        (170 + 8) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----------------+-------------------+\n",
      "|     month|employeeID|     employeeName|total_gross_revenue|\n",
      "+----------+----------+-----------------+-------------------+\n",
      "|1996-07-01|         4|Peacock, Margaret|       11860.450000|\n",
      "|1996-08-01|         8|  Callahan, Laura|        8263.800000|\n",
      "|1996-09-01|         1|   Davolio, Nancy|        6651.000000|\n",
      "|1996-10-01|         4|Peacock, Margaret|       13718.970000|\n",
      "|1996-11-01|         4|Peacock, Margaret|       11311.420000|\n",
      "|1996-12-01|         5| Buchanan, Steven|       10030.820000|\n",
      "|1997-01-01|         4|Peacock, Margaret|       23736.465000|\n",
      "|1997-02-01|         4|Peacock, Margaret|       12121.995000|\n",
      "|1997-03-01|         3| Leverling, Janet|       11599.400000|\n",
      "|1997-04-01|         4|Peacock, Margaret|       13475.990000|\n",
      "|1997-05-01|         3| Leverling, Janet|       18049.600000|\n",
      "|1997-06-01|         2|   Fuller, Andrew|        6882.200000|\n",
      "|1997-07-01|         1|   Davolio, Nancy|       19530.930000|\n",
      "|1997-08-01|         4|Peacock, Margaret|       16485.540000|\n",
      "|1997-09-01|         7|     King, Robert|       13249.860000|\n",
      "|1997-10-01|         1|   Davolio, Nancy|       12414.150000|\n",
      "|1997-11-01|         3| Leverling, Janet|        9598.084000|\n",
      "|1997-12-01|         3| Leverling, Janet|       17636.659000|\n",
      "|1998-01-01|         3| Leverling, Janet|       25705.007500|\n",
      "|1998-02-01|         2|   Fuller, Andrew|       23127.550000|\n",
      "+----------+----------+-----------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Load necessary tables (assuming they are already loaded as shown above)\n",
    "order_details = spark.read.jdbc(url=jdbc_url, table=\"order_details\", properties=connection_properties)\n",
    "orders = spark.read.jdbc(url=jdbc_url, table=\"orders\", properties=connection_properties)\n",
    "employees = spark.read.jdbc(url=jdbc_url, table=\"employees\", properties=connection_properties)\n",
    "\n",
    "# Perform the equivalent operations in PySpark\n",
    "employee_revenue = orders.join(order_details, orders[\"orderID\"] == order_details[\"orderID\"], \"inner\") \\\n",
    "    .groupBy(\n",
    "        F.date_format(F.date_trunc(\"month\", orders[\"orderDate\"]), \"yyyy-MM-dd\").alias(\"month\"),\n",
    "        orders[\"employeeID\"]\n",
    "    ).agg(\n",
    "        F.sum((order_details[\"unitPrice\"] - (order_details[\"unitPrice\"] * order_details[\"discount\"])) * order_details[\"quantity\"]).alias(\"total_gross_revenue\")\n",
    "    )\n",
    "\n",
    "# Rank employees based on total gross revenue\n",
    "ranked_employees = employee_revenue.withColumn(\n",
    "    \"employee_rank\",\n",
    "    F.rank().over(Window.partitionBy(\"month\").orderBy(F.desc(\"total_gross_revenue\")))\n",
    ").filter(\n",
    "    F.col(\"employee_rank\") == 1\n",
    ")\n",
    "\n",
    "# Join with employees to get final result\n",
    "final_result = ranked_employees.join(\n",
    "    employees, ranked_employees[\"employeeID\"] == employees[\"employeeID\"], \"inner\"\n",
    ").select(\n",
    "    ranked_employees[\"month\"],\n",
    "    ranked_employees[\"employeeID\"],\n",
    "    F.concat(employees[\"lastName\"], F.lit(\", \"), employees[\"firstName\"]).alias(\"employeeName\"),\n",
    "    ranked_employees[\"total_gross_revenue\"]\n",
    ")\n",
    "\n",
    "# Show or save the final result as needed\n",
    "final_result.orderBy(F.asc(\"month\"), F.desc(\"total_gross_revenue\")).show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
